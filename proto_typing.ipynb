{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ca74684-6735-45e0-a55b-f5e3f56b0988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A check of the initialization file needs to be done!\n",
      "A check of the survey year file needs to be done!\n",
      "Loading US biological data ...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd \n",
    "import sys \n",
    "from EchoPro import EchoPro\n",
    "epro_2019 = EchoPro(init_file_path='./config_files/initialization_config.yml',\n",
    "                    survey_year_file_path='./config_files/survey_year_2019_config.yml',\n",
    "                    source=3,\n",
    "                    bio_data_type=1,\n",
    "                    age_data_status=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "237b9aaa-098c-4874-832b-bc03e81bad88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 234 ms, sys: 1.61 ms, total: 236 ms\n",
      "Wall time: 235 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Male_ind</th>\n",
       "      <th>Female_ind</th>\n",
       "      <th>n</th>\n",
       "      <th>meanlen</th>\n",
       "      <th>stdlen</th>\n",
       "      <th>TS_lin</th>\n",
       "      <th>TS_sd</th>\n",
       "      <th>TS_log</th>\n",
       "      <th>nM</th>\n",
       "      <th>nF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Haul</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...</td>\n",
       "      <td>[20.0, 20.0, 20.0, 20.0, 20.0, 21.0, 21.0, 21....</td>\n",
       "      <td>[148, 149, 150, 151, 152, 153, 154, 155, 156, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>342</td>\n",
       "      <td>23.385965</td>\n",
       "      <td>2.125845</td>\n",
       "      <td>-40.585259</td>\n",
       "      <td>0.747452</td>\n",
       "      <td>-40.654102</td>\n",
       "      <td>194</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...</td>\n",
       "      <td>[18.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19....</td>\n",
       "      <td>[128, 129, 130, 131, 132, 133, 134, 135, 136, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>535</td>\n",
       "      <td>20.949533</td>\n",
       "      <td>1.400667</td>\n",
       "      <td>-41.557179</td>\n",
       "      <td>0.704258</td>\n",
       "      <td>-41.600977</td>\n",
       "      <td>97</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...</td>\n",
       "      <td>[20.0, 20.0, 20.0, 20.0, 21.0, 21.0, 21.0, 21....</td>\n",
       "      <td>[72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 8...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>167</td>\n",
       "      <td>22.239521</td>\n",
       "      <td>1.247695</td>\n",
       "      <td>-41.043925</td>\n",
       "      <td>0.489027</td>\n",
       "      <td>-41.071140</td>\n",
       "      <td>95</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...</td>\n",
       "      <td>[20.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21....</td>\n",
       "      <td>[68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 7...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>161</td>\n",
       "      <td>23.273292</td>\n",
       "      <td>1.781809</td>\n",
       "      <td>-40.637619</td>\n",
       "      <td>0.638929</td>\n",
       "      <td>-40.686783</td>\n",
       "      <td>93</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...</td>\n",
       "      <td>[20.0, 20.0, 20.0, 20.0, 21.0, 21.0, 21.0, 21....</td>\n",
       "      <td>[63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 7...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>127</td>\n",
       "      <td>22.803150</td>\n",
       "      <td>3.023819</td>\n",
       "      <td>-40.764991</td>\n",
       "      <td>0.883306</td>\n",
       "      <td>-40.892414</td>\n",
       "      <td>64</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Sex  \\\n",
       "Haul                                                      \n",
       "1     [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...   \n",
       "3     [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...   \n",
       "7     [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...   \n",
       "8     [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...   \n",
       "9     [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...   \n",
       "\n",
       "                                                 Length  \\\n",
       "Haul                                                      \n",
       "1     [20.0, 20.0, 20.0, 20.0, 20.0, 21.0, 21.0, 21....   \n",
       "3     [18.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19....   \n",
       "7     [20.0, 20.0, 20.0, 20.0, 21.0, 21.0, 21.0, 21....   \n",
       "8     [20.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21....   \n",
       "9     [20.0, 20.0, 20.0, 20.0, 21.0, 21.0, 21.0, 21....   \n",
       "\n",
       "                                               Male_ind  \\\n",
       "Haul                                                      \n",
       "1     [148, 149, 150, 151, 152, 153, 154, 155, 156, ...   \n",
       "3     [128, 129, 130, 131, 132, 133, 134, 135, 136, ...   \n",
       "7     [72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 8...   \n",
       "8     [68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 7...   \n",
       "9     [63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 7...   \n",
       "\n",
       "                                             Female_ind    n    meanlen  \\\n",
       "Haul                                                                      \n",
       "1     [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  342  23.385965   \n",
       "3     [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  535  20.949533   \n",
       "7     [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  167  22.239521   \n",
       "8     [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  161  23.273292   \n",
       "9     [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  127  22.803150   \n",
       "\n",
       "        stdlen     TS_lin     TS_sd     TS_log   nM   nF  \n",
       "Haul                                                      \n",
       "1     2.125845 -40.585259  0.747452 -40.654102  194  148  \n",
       "3     1.400667 -41.557179  0.704258 -41.600977   97  128  \n",
       "7     1.247695 -41.043925  0.489027 -41.071140   95   72  \n",
       "8     1.781809 -40.637619  0.638929 -40.686783   93   68  \n",
       "9     3.023819 -40.764991  0.883306 -40.892414   64   63  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# code to turn length_US file into a dataframe with expanded frequencies\n",
    "out = pd.read_excel(epro_2019.params['data_root_dir'] + epro_2019.params['filename_length_US'])\n",
    "df = epro_2019.process_length_data_df(out, 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "24fd9fe3-a18f-4786-9602-1db35cc6bfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sex  Length  Frequency\n",
      "Haul                        \n",
      "1       2      20          5\n",
      "1       2      21         13\n",
      "1       2      22         38\n",
      "1       2      23         38\n",
      "1       2      24         16\n"
     ]
    }
   ],
   "source": [
    "df = epro_2019.process_length_data_ds(out, 0)\n",
    "df.set_index('Haul', inplace=True)\n",
    "print(df.head())\n",
    "max_haul_size = df.index.value_counts().max()\n",
    "series_haul = df.groupby('Haul').apply(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "94e49e87-14cd-4b15-af00-90b980d86c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad the numpy arrays of each haul to match the maximum haul size\n",
    "series_haul_pad = series_haul.apply(lambda x: np.vstack((x, np.nan*np.ones((max_haul_size - x.shape[0], 3)))) if x.shape[0] != max_haul_size else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7cc4e915-b1c7-4e50-b957-3f29f77c7370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# series_haul_pad = series_haul_pad.apply(np.transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2a027722-f0c6-4660-bb95-22d8a1f702d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np_haul_pad = series_haul_pad.agg(lambda x: np.hstack(x.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d3fdecb9-8bdf-4fa7-b295-0616a26fdc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np_haul_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "24062294-d5f2-4da5-861e-e85f1052f119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = xr.Dataset(data_vars={\n",
    "#     'Sex': (['Haul'], np_haul_pad[0, :]),\n",
    "#     'Length': (['Haul'], np_haul_pad[1, :]), \n",
    "#     'Frequency': (['Haul'], np_haul_pad[2, :])}, coords={'Haul': df.index})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d747c9-1969-4630-897c-f8122cdd0e05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2bedfb-814c-4537-91cb-1fc61109a69a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "776da092-1477-4d7f-837c-80f885165cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.getsizeof(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3e45370-71af-4383-89ad-22f6abd5f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# max_n = df['n'].max()\n",
    "# sex_series = df.Sex.apply(lambda x: np.concatenate([x, np.nan*np.ones(max_n - len(x))])  if len(x) != max_n else x)\n",
    "# sex_stacked = np.vstack(sex_series)\n",
    "\n",
    "# length_series = df.Length.apply(lambda x: np.concatenate([x, np.nan*np.ones(max_n - len(x))])  if len(x) != max_n else x)\n",
    "# length_stacked = np.vstack(length_series)\n",
    "\n",
    "# male_ind_series = df.Male_ind.apply(lambda x: np.concatenate([x, np.nan*np.ones(max_n - len(x))])  if len(x) != max_n else x)\n",
    "# male_ind_stacked = np.vstack(male_ind_series)\n",
    "\n",
    "# female_ind_series = df.Female_ind.apply(lambda x: np.concatenate([x, np.nan*np.ones(max_n - len(x))])  if len(x) != max_n else x)\n",
    "# female_ind_stacked = np.vstack(female_ind_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0124d21-ba38-4a9b-9462-10932ee79263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = xr.Dataset(dict(\n",
    "#     Sex=(['haul', 'index'], sex_stacked), \n",
    "#     Length=(['haul', 'index'], length_stacked),\n",
    "#     Male_ind=(['haul', 'index'], male_ind_stacked),\n",
    "#     Female_ind=(['haul', 'index'], female_ind_stacked), \n",
    "#     n=(['haul'], df.n.to_numpy()),\n",
    "#     meanlen=(['haul'], df.meanlen.to_numpy()),\n",
    "#     stdlen=(['haul'], df.stdlen.to_numpy()),\n",
    "#     TS_lin=(['haul'], df.TS_lin.to_numpy()),\n",
    "#     TS_sd=(['haul'], df.TS_sd.to_numpy()),\n",
    "#     TS_log=(['haul'], df.TS_log.to_numpy()),\n",
    "#     nM=(['haul'], df.nM.to_numpy()),\n",
    "#     nF=(['haul'], df.nF.to_numpy())\n",
    "# ), coords={\n",
    "#     'haul': df.index.to_numpy(),\n",
    "#     'index' : range(max_n)\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04b3b5f5-fb26-4a07-966b-3ba338372a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3798aa49-ed40-444b-b258-bbcc51584136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d62b2f7c-fb66-4e35-baf0-64a0a0f86455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# out = pd.read_excel(epro_2019.params['data_root_dir'] + epro_2019.params['filename_catch_US'])\n",
    "# df = epro_2019.process_catch_data(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e5fb073-9c81-4c02-99bb-90057a32c5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# out = pd.read_excel(epro_2019.params['data_root_dir'] + epro_2019.params['filename_specimen_US'])\n",
    "# df = epro_2019.process_specimen_data(out, 0)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db90d3d3-bc43-4910-ab5b-6683d1ebab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_us_df, length_us_df, trawl_us_df, gear_us_df, specimen_us_df = epro_2019.load_biological_data_us()\n",
    "# catch_can_df, length_can_df, trawl_can_df, gear_can_df, specimen_can_df = epro_2019.load_biological_data_canada()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cda9f04-3f37-418e-bca9-a0b6e0e009f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# out = pd.read_excel(epro_2019.params['data_root_dir'] + epro_2019.params['filename_length_US'])\n",
    "# df = epro_2019.process_length_data(out, 0)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5074618-ffd1-4128-8716-1fe9a6c3dced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epro_2019.specimen_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db446092-5035-4008-8b6e-4024cb08b1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specimen_ds = epro_2019.specimen_df.to_xarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c199fb6f-f1b5-4bae-be23-a045cf71398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# select the indices that do not have nan in either Length or Weight\n",
    "# len_wgt_nonull = np.logical_and(specimen_ds.Length.notnull(), specimen_ds.Weight.notnull())\n",
    "\n",
    "# x = np.log10(specimen_ds.Length.sel(Haul=len_wgt_nonull)).values\n",
    "# y = np.log10(specimen_ds.Weight.sel(Haul=len_wgt_nonull)).values\n",
    "\n",
    "# p = np.polyfit(x, y, 1)  # linear regression \n",
    "\n",
    "# print(y[np.isnan(y)])\n",
    "\n",
    "# print(x.shape)\n",
    "# print(y.shape)\n",
    "\n",
    "# print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6fbbde8-55ab-4c26-87e0-7a2c7abf4239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specimen_ds.sel(Haul=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520b5260-b213-4525-9551-0e584ffd73b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:echopro_conda] *",
   "language": "python",
   "name": "conda-env-echopro_conda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
